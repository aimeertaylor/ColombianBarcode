---
output:
  pdf_document: default
  html_document: default
---


```{r markdown_setup, include = FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, include=FALSE, cache=TRUE, cache.comments = FALSE, 
                      fig.pos = 'H', fig.width = 8, fig.height = 6, dev = 'png', dpi = 300)
```

```{r}
rm(list = ls())
library(igraph) # For network plot
library(proxy) # for dist
library(RColorBrewer)
library(gtools) # for perturbations

set.seed(10) # For jitter on network plot Layout
load('/Users/aimeet/Documents/BroadLaptop/ColombianBarcode/RData/Result.RData') # Load data
load('/Users/aimeet/Documents/BroadLaptop/ColombianBarcode/RData/SNPData.RData') # For Layout sites dates etc
Result$sample1 = as.character(Result$sample1) # Convert factors to characters
Result$sample2 = as.character(Result$sample2)

# Load geo_dist info and raw data 
load('../RData/geo_dist_info.RData')
attach(geo_dist_info)

# Names of within and across comparisons
inter = apply(pairwise_site_distance[,1:2], 1, function(x){paste(sort(x), collapse = '_')})
intra <- c('Guapi_Guapi',
           'Tumaco_Tumaco',
           'Tado_Tado', 
           'Buenaventura_Buenaventura', 
           'Quibdo_Quibdo')
intra_inter = c(intra, inter)

# Subset results for haps across only
Result_inter = Result #[Result$site_comp %in% names(pairwise_site_distance_all[pairwise_site_distance_all > 0]), ]
Rownames = unique(c(Result_inter$sample1, Result_inter$sample2))
nSamples = length(Rownames)  
```

```{r}
# Function that takes a matrix of haplotypes and a fuzzy matching parameter
# and returns a list of distinct haplotypes with two or more corrsponding samples
enlist_distinct_haps = function(Haplotypes, no_diff_allowed){
  
  # Use dist rather than strings to allow some fuzzy matches between haps
  Hap_identity_matrix = as.matrix(dist(Haplotypes,  function(x,y){sum(x != y, na.rm = TRUE) <= no_diff_allowed }))
  repeat_store = list() # List of samples with repeat haplotypes and all the things they are the same as
  
  for(Row in Rownames_withIBD1_comp){
    x = Hap_identity_matrix[Row,] == 1 # For each row, are any 1s are observed?
    if(any(x)){ # If yes were any colnames of said row previously recorded as a repeat?
      z = names(x)[x] %in% names(repeat_store)
      if(all(!z)){ # If not add row with corresponding colnames
        repeat_store[[Row]] = names(x)[x] 
      }
    }
  }
  # For each element in repeat store, add its name as an entry
  for(x in names(repeat_store)){repeat_store[[x]] <- c(x, repeat_store[[x]])}
  
  # Check no repeat sample names in the store... 
  if(any(table(unlist(repeat_store)) > 1)){
    print(sprintf('Some samples are labelled by more than one haplotype when %s diffs allowed', no_diff_allowed))}
  
  # Rename
  no_repeats = length(repeat_store)
  names(repeat_store) <- paste('hap', 1:no_repeats, sep = '')
  
  return(repeat_store)
}
```


```{r}
ind_IBD1 = Result_inter$IBD == 1 # IBD = 1 comparisons

# Fuzzy matching required because despite IBS >= IBD in general (plot(Result_inter$IBS, Result_inter$IBD))
sum(Result_inter$IBS[ind_IBD1] < 1) # There are 82 IBD == 1 with IBS < 1
sum(Result_inter$IBD[Result_inter$IBS == 1] < 1) # There are zero IBS = 1 with IBD < 1

# Majority of samples have one or more IBD == 1 comparison?
Rownames_withIBD1_comp = unique(c(Result_inter$sample1[ind_IBD1], Result_inter$sample2[ind_IBD1]))
nSamples_withIBD1_comp = length(Rownames_withIBD1_comp)
# nSamples_withIBD1_comp / nSamples # The majority

# Extract all haplotypes 
Haplotypes = SNPData[Rownames_withIBD1_comp, 6:255] # replace Rownames_withIBD1_comp with Rownames to relax IBD == 1 comparison constraint

# How fuzzy does matching need to be to get a stable number of distinct haplotypes? 
no_diffs_allowed = 0:20
no_distinct_haps = sapply(no_diffs_allowed, function(x){length(enlist_distinct_haps(Haplotypes, x))})
plot(no_diffs_allowed, no_distinct_haps) # Conclusion: seems 4:15 are stable (allow 4 = no duplicate labels)
repeat_store = enlist_distinct_haps(Haplotypes, 4) 
repeat_haps = names(repeat_store)
no_repeat_haps = length(repeat_haps)

# Unpackage repeat_store s.t. each sample is labelled with a single haplotype
hap0s = array('Singleton', dim = nSamples, dimnames = list(Rownames)) # Make a vector entirely of Singletons
hap_labels = rep(names(repeat_store), sapply(repeat_store, length)) # Unpackage non singletons
names(hap_labels) = unlist(repeat_store) # Add sample names
hap_labels = c(hap_labels, hap0s[!Rownames %in% names(hap_labels)])  # Add the singletons non repeat sample names
all(Rownames %in% names(hap_labels)) # Check all accounted for

# Create colours for the haplotypes
cols = colorRampPalette(brewer.pal(12, "Paired")) # Function
hap.cols <- c("#D3D3D3FF", cols(no_repeat_haps)) # White then colours
names(hap.cols) = c('Singleton', repeat_haps)

# Colour edges by haplotypes (rememver only edges > 0 have edge weights)
Result$hap = 'Singleton'
Result$hap[ind_IBD1] = hap_labels[Result_inter$sample1[ind_IBD1]]

# Check the labels are symmetrical over samples (only true if samples have unique haplotype labels - choose number of diffs appropriately)
all(hap_labels[Result_inter$sample1[ind_IBD1]] == hap_labels[Result_inter$sample2[ind_IBD1]])
```


```{r}
#=================================================================
# Calculate proportions by time and site comp
# Adapted from child_IBD_IBS
#=================================================================
nrep <- 1000 # For bootstrap confidence intervals
interval <- 50 # The resolution of time bins in weeks
max_time_dist = max(as.numeric(Result$time_dist))
time_breaks <- seq(0, max_time_dist, interval) 
max_time_breaks = max(time_breaks)
if(max_time_breaks < max_time_dist){time_breaks = c(time_breaks, max_time_breaks + interval)}
time_bins = time_breaks[-length(time_breaks)] # The time bins value are the min for each bin
no_time_bins = length(time_bins)
site_comps = unique(Result$site_comp)
no_site_comps = length(site_comps)
set.seed(1) # For reproducibility

# Add time bins 
Result$time_bins = NA
for(i in 1:no_time_bins){
  ind <- (as.numeric(Result$time_dist) >= time_breaks[i]) & (as.numeric(Result$time_dist) < time_breaks[i+1])
  Result$time_bins[ind] = time_bins[i]
}

# Stores (inc. those where intervals are broken down into site_comps and time bins)
proportions_dist <- array(dim = c(no_site_comps, 2), dimnames = list(site_comps, c('IBD', 'IBS')))
proportions_dist_deltas <- array(dim = c(no_site_comps, 2, nrep), dimnames = list(site_comps,c('IBD', 'IBS'), NULL))
proportions_dist_grouped_hap = array(0, dim = c(length(unique(hap_labels)), no_site_comps, 3), 
                                 dimnames = list(unique(hap_labels), site_comps, c('lowIBD','highIBD', 'all')))

# Function to extract proportion related based on bootstrap
X <- array(dim = c(2, nrep)) # For array in apply(fun_boot)
fun_boot <- function(x, denom, actual_IBD, actual_IBS){
  X <- cbind(x = mean(actual_IBD[sample(denom, size = denom, replace = TRUE)]),
             y = mean(actual_IBS[sample(denom, size = denom, replace = TRUE)]))
  return(X)
}

# Calculate proportions with site
for(i in site_comps){
  
  # Extract data
  ind <- Result$site_comp == i 
  actual_IBD <- Result$IBD_tail[ind]
  actual_IBS <- Result$IBS_tail[ind]
  denom = sum(ind)
  
  # Proportions of different hap bins
  hap_bin_breakdown_all = table(Result$hap[ind])
  hap_bin_breakdown_highIBD = table(Result$hap[ind][as.logical(Result$IBD_tail[ind])])
  hap_bin_breakdown_lowIBD = table(Result$hap[ind][!as.logical(Result$IBD_tail[ind])])

  proportions_dist_grouped_hap[names(hap_bin_breakdown_all), i, 'all'] = hap_bin_breakdown_all/denom
  proportions_dist_grouped_hap[names(hap_bin_breakdown_highIBD), i, 'highIBD'] = hap_bin_breakdown_highIBD/denom
  proportions_dist_grouped_hap[names(hap_bin_breakdown_lowIBD), i, 'lowIBD'] = hap_bin_breakdown_lowIBD/denom
   
  # Observed proportion 
  proportions_dist[i, 'IBD'] <- mean(actual_IBD)
  proportions_dist[i, 'IBS'] <- mean(actual_IBS)
  
  # Boostrap proportions
  bootstrap <- apply(X, 2, FUN = fun_boot, denom, actual_IBD, actual_IBS)
  deltas <- bootstrap - proportions_dist[i, ]
  proportions_dist_deltas[i, ,] <- deltas
}

# # Check proptions wrt time the same if grouped or not: Yes 
# cbind(rowSums(t(proportions_dist_grouped_hap[,,'highIBD']), na.rm = TRUE), proportions_dist[,'IBD'])

# Extract 95% percentiles and save
deltaCIs_dist <- apply(proportions_dist_deltas, c(1,2), quantile, probs = c(0.025, 0.975), na.rm = TRUE)
```

```{r, include = TRUE}
par(mfrow = c(1,1), family = 'serif', mar = c(7,5,1,1))
threshold_IBD = 0.5

# Break down it to site comparsion contributions 
CIs <- rbind(proportions_dist[inter,'IBD'], proportions_dist[inter, 'IBD']) + deltaCIs_dist[,inter,'IBD']
X <- barplot(proportions_dist_grouped_hap[,inter,'highIBD'], las = 2, xlab = '', ylim = c(0,max(CIs)), xaxt = 'n',
             ylab = bquote('Proportion of'~~italic(widehat(r))>.(round(threshold_IBD, 1))), 
             cex.names = 0.5, col = hap.cols[rownames(proportions_dist_grouped_hap)])
segments(y0 = CIs[1,], y1 = CIs[2,], x0 = X, x1 = X)
# legend(y = max(CIs), x = 0, fill = hap.cols[1:22], bty = 'n',legend = names(hap.cols[1:22]), cex = 1)
# legend(y = max(CIs), x = X[1]+0.2, fill = hap.cols[-(1:22)], bty = 'n',legend = names(hap.cols[-(1:22)]), cex = 1)

# x labels rotate 60 degrees, srt=60
text(x = X, y = -0.01, srt = 40, adj= 1, xpd = TRUE,
     labels = c(do.call(rbind,strsplit(intra, split = '_'))[,1], 
                sapply(inter, function(x)gsub('_', ' ',x))), cex=1)

# Grouped version 
# X <- barplot(proportions_dist_grouped_hap[,intra_inter,'all'], las = 2, xlab = '', 
#              ylab = expression('Proportion of'~italic(widehat(r))), 
#              cex.names = 0.5, col = hap.cols[rownames(proportions_dist_grouped_hap)])
```

```{r, include = TRUE}
par(mfrow = c(1,1), family = 'serif', mar = c(7,5,1,1))
threshold_IBD = 0.5

# Break down it to site comparsion contributions 
CIs <- rbind(proportions_dist[intra_inter,'IBD'], proportions_dist[intra_inter, 'IBD']) + deltaCIs_dist[,intra_inter,'IBD']
X <- barplot(proportions_dist_grouped_hap[,intra_inter,'highIBD'], las = 2, xlab = '', ylim = c(0,max(CIs)), xaxt = 'n',
             ylab = bquote('Proportion of'~~italic(widehat(r))>.(round(threshold_IBD, 1))), 
             cex.names = 0.5, col = hap.cols[rownames(proportions_dist_grouped_hap)])
segments(y0 = CIs[1,], y1 = CIs[2,], x0 = X, x1 = X)
# legend(y = max(CIs), x = X[length(X)-2], fill = hap.cols[1:22], bty = 'n',legend = names(hap.cols[1:22]), cex = 1)
# legend(y = max(CIs), x = X[length(X)], fill = hap.cols[-(1:22)], bty = 'n',legend = names(hap.cols[-(1:22)]), cex = 1)

# x labels rotate 60 degrees, srt=60
text(x = X, y = -0.01, srt = 40, adj= 1, xpd = TRUE,
     labels = c(do.call(rbind,strsplit(intra, split = '_'))[,1], 
                sapply(inter, function(x)gsub('_', ' ',x))), cex=1)

```